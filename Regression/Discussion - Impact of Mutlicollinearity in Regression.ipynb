{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impact of Mutlicollinearity \n",
    "\n",
    "In this note, we will introduce multicolinearity, and explain how it influences regression analysis. We simulate data by generating dependent and independent variables.\n",
    "\n",
    "### What is multicollinearity?\n",
    "\n",
    "Collinearity occurs when two predictor variables (e.g., x1 and x2) in a multiple regression have a non-zero correlation. Multicollinearity occurs when more than two predictor variables (e.g., x1, x2 and x3) are inter-correlated. See [the Psychological Statistics blog](http://psychologicalstatistics.blogspot.com/2013/11/multicollinearity-and-collinearity-in.html).\n",
    "In most situations in which you would use regression (apart from certain designed experiments) multicollinearity always exists. So if a method section ever claims that “multicollinearity is not present”, generally this will be untrue. A better statement to make is something along the lines of “there were no problems with multicollinearity.\n",
    "\n",
    "\n",
    "### Does multicollinearity matter?\n",
    "\n",
    "The existence of multicollinearity has no impact on the overall regression model. It also should not generally have an impact on predictions made using the overall model and $R^2$. However, if you are interested in the effects of individual predictors, like what predictors are more important, multicollinearity will be a big problem. In the following I will explain the impact by a simulation.\n",
    "\n",
    "### How to detect multicollinearity?\n",
    "\n",
    "To determine multicollinearity, we can compute [Variance Inflation Factor (VIF)](https://etav.github.io/python/vif_factor_python.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if '/Users/hhhung/anaconda/lib/python3.4/site-packages' not in sys.path:\n",
    "    sys.path.append('/Users/hhhung/anaconda/lib/python3.4/site-packages')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from sklearn import linear_model\n",
    "from sklearn import grid_search\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import cross_val_score, train_test_split\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate data\n",
    "\n",
    "We generate 2000 data points, each variable has a normal distribution and the target variable is obtained by the following relation:\n",
    "$$ y = a+ bx_1 +cx_2 +dx_3 +ex_{col} + \\epsilon,$$\n",
    "where $x_{col}$ has relation with $x_1$ and $x_3$. We usually call $x_1, x_2, \\cdots$, as predictors, or independent variables. $y$ is dependent (target) variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.random.random_sample((2000,)) \n",
    "x2 = np.random.random_sample((2000,)) \n",
    "x3 = np.random.random_sample((2000,)) \n",
    "          \n",
    "x_col = 2*x1       \n",
    "err = np.random.normal(0, 10, 2000)\n",
    "\n",
    "y = 10*x1 + 3*x2 + x3 + 4*x_col + err\n",
    "\n",
    "data = pd.DataFrame({'x1': x1, 'x2': x2, 'x3': x3, 'x_col': x_col, 'y': y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example, $a=0$, $b=10$, $c=3$, $d=1$ and $e=4$. There exists multicollinearity since $x_{col}$ is a linear combination in terms of $x_1$ and $x_3$. Therefore, the reduced relation should be \n",
    "$$ y = 18x_1 +3x_2 +x_3 + \\epsilon.$$\n",
    "Here we generate irreducible errors using a normal distribution with $\\sigma=10$. Note that since the data are generated using standard normal distribution, we don't have to worry about the procedures to standardize variables. As long as the regression coefficients are significant, we can compare the amplitudes as importance. See [How to Identify the Most Important Predictor Variables in Regression Models](http://blog.minitab.com/blog/adventures-in-statistics-2/how-to-identify-the-most-important-predictor-variables-in-regression-models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x_col</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.524387</td>\n",
       "      <td>0.978207</td>\n",
       "      <td>0.057427</td>\n",
       "      <td>5.343874</td>\n",
       "      <td>38.565558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.814996</td>\n",
       "      <td>0.160209</td>\n",
       "      <td>0.626270</td>\n",
       "      <td>8.249964</td>\n",
       "      <td>52.327896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008605</td>\n",
       "      <td>0.833534</td>\n",
       "      <td>0.219359</td>\n",
       "      <td>0.186046</td>\n",
       "      <td>-0.093717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.391307</td>\n",
       "      <td>0.915240</td>\n",
       "      <td>0.487689</td>\n",
       "      <td>4.013074</td>\n",
       "      <td>12.429257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.731593</td>\n",
       "      <td>0.208704</td>\n",
       "      <td>0.840829</td>\n",
       "      <td>7.415927</td>\n",
       "      <td>32.273304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3     x_col          y\n",
       "0  0.524387  0.978207  0.057427  5.343874  38.565558\n",
       "1  0.814996  0.160209  0.626270  8.249964  52.327896\n",
       "2  0.008605  0.833534  0.219359  0.186046  -0.093717\n",
       "3  0.391307  0.915240  0.487689  4.013074  12.429257\n",
       "4  0.731593  0.208704  0.840829  7.415927  32.273304"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson's correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.47825969322884698, 7.7466612747876968e-115)\n",
      "(0.092185642624021416, 3.6452811056544282e-05)\n",
      "(-0.036101299331034571, 0.10652396762121712)\n",
      "(0.47825969322884698, 7.7466612747876968e-115)\n"
     ]
    }
   ],
   "source": [
    "print (stats.pearsonr(x1, y))\n",
    "print (stats.pearsonr(x2, y))\n",
    "print (stats.pearsonr(x3, y))\n",
    "print (stats.pearsonr(x_col, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relation betweem $x_3$ and $y$ is not obvious. Both $x_1$ and $x_{col}$ are similarly important to $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5oAAADQCAYAAABm3h4cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10bd76a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(13, 3))\n",
    "ax = plt.subplot(141)\n",
    "plt.hist2d(x1, y, bins=40)\n",
    "plt.xlabel('x1', fontsize=15)\n",
    "plt.ylabel('y', fontsize=15)\n",
    "plt.colorbar()\n",
    "\n",
    "ax = plt.subplot(142)\n",
    "plt.hist2d(x2, y, bins=40)\n",
    "plt.xlabel('x2', fontsize=15)\n",
    "plt.colorbar()\n",
    "\n",
    "ax = plt.subplot(143)\n",
    "plt.hist2d(x3, y, bins=40)\n",
    "plt.xlabel('x3', fontsize=15)\n",
    "plt.colorbar()\n",
    "\n",
    "ax = plt.subplot(144)\n",
    "plt.hist2d(x_col, y, bins=40)\n",
    "plt.xlabel('x_col', fontsize=15)\n",
    "plt.colorbar()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinary least square on ALL variables\n",
    "\n",
    "First let's simply take all predictors in regression. We have the mean absolute error 7.98 and $R^2$ = 0.61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.73983545012\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.610</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.609</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1040.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 06 Feb 2018</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:32:45</td>     <th>  Log-Likelihood:    </th> <td> -7379.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2000</td>      <th>  AIC:               </th> <td>1.476e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1997</td>      <th>  BIC:               </th> <td>1.478e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    3.6451</td> <td>    0.128</td> <td>   28.553</td> <td> 0.000</td> <td>    3.395     3.895</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    3.7050</td> <td>    0.629</td> <td>    5.888</td> <td> 0.000</td> <td>    2.471     4.939</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0861</td> <td>    0.630</td> <td>    0.137</td> <td> 0.891</td> <td>   -1.150     1.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x_col</th> <td>    7.2903</td> <td>    0.255</td> <td>   28.553</td> <td> 0.000</td> <td>    6.790     7.791</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.019</td> <th>  Durbin-Watson:     </th> <td>   1.961</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.990</td> <th>  Jarque-Bera (JB):  </th> <td>   0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.007</td> <th>  Prob(JB):          </th> <td>   0.985</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.988</td> <th>  Cond. No.          </th> <td>7.91e+15</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.610\n",
       "Model:                            OLS   Adj. R-squared:                  0.609\n",
       "Method:                 Least Squares   F-statistic:                     1040.\n",
       "Date:                Tue, 06 Feb 2018   Prob (F-statistic):               0.00\n",
       "Time:                        00:32:45   Log-Likelihood:                -7379.1\n",
       "No. Observations:                2000   AIC:                         1.476e+04\n",
       "Df Residuals:                    1997   BIC:                         1.478e+04\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "x1             3.6451      0.128     28.553      0.000         3.395     3.895\n",
       "x2             3.7050      0.629      5.888      0.000         2.471     4.939\n",
       "x3             0.0861      0.630      0.137      0.891        -1.150     1.322\n",
       "x_col          7.2903      0.255     28.553      0.000         6.790     7.791\n",
       "==============================================================================\n",
       "Omnibus:                        0.019   Durbin-Watson:                   1.961\n",
       "Prob(Omnibus):                  0.990   Jarque-Bera (JB):                0.030\n",
       "Skew:                           0.007   Prob(JB):                        0.985\n",
       "Kurtosis:                       2.988   Cond. No.                     7.91e+15\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 6.52e-29. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[['x1', 'x2', 'x3', 'x_col']]\n",
    "Y = data['y']\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "print (np.mean(abs(np.array(Y)-np.array(model.predict(X)))))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, note the coefficients make no sense. If we sort the importance by the coefficients (even consider significant variable $x_1$, $x_2$ and $x_{col}$), the most importance variable is $x_{col}$, and then $x_1$ and $x_2$ are equally important. In this case, we will make wrong judgement to explain the data.\n",
    "\n",
    "## Ordinary least square after removing multicollinear variables\n",
    "\n",
    "Now let's only consider truely independent variables: $x_1, x_2, x_3$ in regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.73983545012\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.610</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.609</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1040.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 06 Feb 2018</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:32:51</td>     <th>  Log-Likelihood:    </th> <td> -7379.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2000</td>      <th>  AIC:               </th> <td>1.476e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1997</td>      <th>  BIC:               </th> <td>1.478e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td>   18.2256</td> <td>    0.638</td> <td>   28.553</td> <td> 0.000</td> <td>   16.974    19.477</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th> <td>    3.7050</td> <td>    0.629</td> <td>    5.888</td> <td> 0.000</td> <td>    2.471     4.939</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th> <td>    0.0861</td> <td>    0.630</td> <td>    0.137</td> <td> 0.891</td> <td>   -1.150     1.322</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.019</td> <th>  Durbin-Watson:     </th> <td>   1.961</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.990</td> <th>  Jarque-Bera (JB):  </th> <td>   0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.007</td> <th>  Prob(JB):          </th> <td>   0.985</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.988</td> <th>  Cond. No.          </th> <td>    3.19</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.610\n",
       "Model:                            OLS   Adj. R-squared:                  0.609\n",
       "Method:                 Least Squares   F-statistic:                     1040.\n",
       "Date:                Tue, 06 Feb 2018   Prob (F-statistic):               0.00\n",
       "Time:                        00:32:51   Log-Likelihood:                -7379.1\n",
       "No. Observations:                2000   AIC:                         1.476e+04\n",
       "Df Residuals:                    1997   BIC:                         1.478e+04\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "x1            18.2256      0.638     28.553      0.000        16.974    19.477\n",
       "x2             3.7050      0.629      5.888      0.000         2.471     4.939\n",
       "x3             0.0861      0.630      0.137      0.891        -1.150     1.322\n",
       "==============================================================================\n",
       "Omnibus:                        0.019   Durbin-Watson:                   1.961\n",
       "Prob(Omnibus):                  0.990   Jarque-Bera (JB):                0.030\n",
       "Skew:                           0.007   Prob(JB):                        0.985\n",
       "Kurtosis:                       2.988   Cond. No.                         3.19\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[['x1', 'x2', 'x3']]\n",
    "Y = data['y']\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "print (np.mean(abs(np.array(Y)-np.array(model.predict(X)))))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean absolute error and $R^2$ are still the same, but now coefficients make more sense for us. The predictor importance is simply consistent with the rank of coefficients' amplitude: $x_1$ > $x_2$ > $x_3$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute VIF in Python\n",
    "\n",
    "So, how to detect multicollinearity in our data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patsy import dmatrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = \"+\".join([\"x1\", \"x2\", \"x3\", \"x_col\"])\n",
    "\n",
    "y, X = dmatrices('y ~' + features, data, return_type='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hhhung/anaconda/lib/python3.4/site-packages/statsmodels/stats/outliers_influence.py:167: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF Factor</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.526188</td>\n",
       "      <td>Intercept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inf</td>\n",
       "      <td>x1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000632</td>\n",
       "      <td>x2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000867</td>\n",
       "      <td>x3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>inf</td>\n",
       "      <td>x_col</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VIF Factor   features\n",
       "0    9.526188  Intercept\n",
       "1         inf         x1\n",
       "2    1.000632         x2\n",
       "3    1.000867         x3\n",
       "4         inf      x_col"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif[\"features\"] = X.columns\n",
    "vif.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As long as VIF > 1, it hints existence of multicollinearity on the variables. VIF >5 means severe multicollinearity. From the result, we can $x_1$ and $x_{col}$ are even infinite (away beyond 1). Therefore there exists severe multicollinarity between $x_1$ and $x_{col}$. Next after we remove $x_{col}$ and recompute VIF for each variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF Factor</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.526188</td>\n",
       "      <td>Intercept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.001033</td>\n",
       "      <td>x1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000632</td>\n",
       "      <td>x2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000867</td>\n",
       "      <td>x3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VIF Factor   features\n",
       "0    9.526188  Intercept\n",
       "1    1.001033         x1\n",
       "2    1.000632         x2\n",
       "3    1.000867         x3"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = \"+\".join([\"x1\", \"x2\", \"x3\"])\n",
    "\n",
    "y, X = dmatrices('y ~' + features, data, return_type='dataframe')\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif[\"features\"] = X.columns\n",
    "vif.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we see all variables have VIF=1, and the variables are independent of each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
